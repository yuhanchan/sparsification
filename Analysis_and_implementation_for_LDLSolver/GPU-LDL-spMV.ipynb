{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "using CUDA.CUSPARSE\n",
    "using LinearAlgebra\n",
    "using Laplacians\n",
    "using BenchmarkTools\n",
    "using SparseArrays\n",
    "using Profile, ProfileSVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph that is used to compute\n",
    "For now, using the `pure_random_graph()` API in `Laplacians` library to generate an input graph to keep things simple. My goal at this stage is familiar with Julia and write a working GPU accelerated PCG implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000×500000 SparseMatrixCSC{Float64, Int64} with 999998 stored entries:\n",
       "⢻⡲⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⢳⡀⠈⠙⠲⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⢳⡀⠀⠀⠀⠈⠙⠲⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠈⠙⠲⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠲⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠲⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠲⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠲⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠲⢤⣀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠲⢤⣀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
       "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a random graph for now: to keep the framework simple\n",
    "G = pure_random_graph(500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute UR\n",
    "`UR` depends on a random projection matrix. To eliminate the randomness, UR is precomputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000×52 Matrix{Float64}:\n",
       "  1.56352    0.0264318  -0.405654   …  -2.15465     -0.339218    2.29699\n",
       " -0.771098   0.291839    1.74057       -0.376628    -1.0792     -3.38268\n",
       " -2.44124    1.31332    -0.309925       1.21666     -0.554592   -4.05069\n",
       " -1.44046    1.88636    -2.02203        0.244647     1.29985     2.17637\n",
       "  1.47198   -4.30914    -2.70354        5.36348     -0.654591    0.0805611\n",
       " -1.26504    1.63984     1.73258    …   0.486712     0.60848     0.845595\n",
       "  0.67612   -0.572674    2.35618        0.00995473   1.59809     1.24164\n",
       " -1.22466   -2.79176     0.80713       -2.10519      1.50387    -0.241062\n",
       "  1.81701    0.397472    1.47036        0.510398    -2.92432    -1.4947\n",
       " -1.36539   -0.834711    0.158229      -4.98645      0.135314   -0.357961\n",
       " -2.73702    1.20562     1.31942    …  -1.9408      -0.427102    0.368647\n",
       "  1.10546    0.395197   -0.162306       0.378567    -0.0275037   0.080736\n",
       "  2.26089   -1.20489    -1.07327       -0.0647563   -2.36894     0.0616504\n",
       "  ⋮                                 ⋱                ⋮          \n",
       "  0.117248  -0.0298152  -0.0492988      0.0280894   -0.0395906   0.758058\n",
       " -0.542138   0.123927    1.75713       -0.496774    -0.139314    1.27899\n",
       " -1.09138   -0.599598   -0.658017   …  -1.54147     -2.44658     0.0558906\n",
       "  0.357291   0.0817879   0.598025      -2.42676      1.05247     1.82261\n",
       " -1.47383    1.10166     2.40015       -1.00716     -0.0673783  -1.38869\n",
       " -2.64408    1.13503    -1.24939       -1.60029     -1.07388     1.5726\n",
       "  0.961623  -0.650863   -0.326127      -1.51774     -0.745225   -0.221338\n",
       " -0.599424   1.53029    -0.794678   …   0.56708      0.518791    1.58764\n",
       "  0.772427   0.409667   -0.612167       0.874648     0.943458    0.0393999\n",
       " -0.658168  -2.33186     2.28523       -0.391648    -1.13581    -0.913791\n",
       " -0.101738   0.439867   -2.66735       -0.970204    -0.611392   -0.127967\n",
       "  0.231202   0.574176    1.56246        1.2937      -0.825953    0.364686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to fix the random projection matrix\n",
    "JLfac = 4.0\n",
    "\n",
    "n = size(G,1)\n",
    "k = round(Int, JLfac*log(n)) # number of dims for JL, natrual log\n",
    "U = wtedEdgeVertexMat(G) # equal to W, mxn\n",
    "m = size(U,1)\n",
    "\n",
    "R = randn(Float64, m,k) # equal to Q, JL projection matrix, mxk\n",
    "\n",
    "UR = U'*R; # nxk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CPU baseline & Ground truth\n",
    "the following section using the code from yuhan's repo as a CPU baseline as well as the ground truth to verify correctness. tollerance is set to 0.0001 to increase the iteration in each pcg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_V (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the reference function from Yuhan's repo that uses Laplacian's library\n",
    "function compute_V(a, UR)\n",
    "  f = approxchol_lap(a,tol=1e-2); # a is the weight matrix loaded from file, nxn\n",
    "\n",
    "  V = zeros(n,k)\n",
    "  print(\"Time to solve Lap: \")\n",
    "  @time for i in 1:k\n",
    "    V[:,i] = f(UR[:,i]) # f is the linear solver, solve for x in Ax=b\n",
    "  end\n",
    "  \n",
    "  return V # V here is the Z in paper\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to solve Lap:   1.153664 seconds (1.93 k allocations: 1.550 GiB, 6.10% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000×52 Matrix{Float64}:\n",
       " -0.136154   0.221333   -0.101415  …  -0.864206   -0.543875  -0.637303\n",
       " -1.33927    0.101885    0.94094       0.274264   -0.600522  -2.22005\n",
       " -0.496564   0.31435    -0.738116      0.151975   -0.148009  -1.35155\n",
       " -2.01569    0.574576    1.47215       0.420305    0.121864  -0.233282\n",
       " -1.09486   -0.782095   -0.288486      1.64332    -0.30036   -2.40688\n",
       " -0.653569  -0.0810101  -1.21161   …   0.017349    0.272805  -0.0757558\n",
       "  1.74127   -0.510598   -0.591395      0.0861215   0.381633   0.709085\n",
       " -2.00904    0.142638    2.17329      -0.726002    0.188597  -1.00654\n",
       " -1.25829   -0.407155    3.32424       1.46801    -0.522331   0.350373\n",
       " -0.395821   0.852829    0.687504     -1.16199     0.182291  -1.70919\n",
       " -3.02147    1.00814     0.209637  …   0.454204    0.171743  -3.37195\n",
       " -0.501783  -1.26335    -2.27705       1.20961     0.949149   0.77482\n",
       "  0.302677  -0.933872   -2.35225      -1.79625    -0.591203  -0.496129\n",
       "  ⋮                                ⋱               ⋮         \n",
       " -6.79343   -5.61047     1.4999       -1.96425     3.51561    1.9123\n",
       " -6.16174   -5.93651     2.5438       -0.69752    -0.217299   3.26072\n",
       " -6.71098   -6.66004     0.128651  …  -1.74221    -2.52456    2.03762\n",
       " -2.13122   -6.09355    -2.79915      -3.49407     3.3962     2.94343\n",
       " -3.96234   -5.07368    -0.997027     -2.07447     2.27635   -0.267876\n",
       " -5.40193   -3.49376    -1.46473      -0.859093    0.471503   0.938455\n",
       " -1.79623   -5.27965    -0.54147      -0.776543    0.800157  -0.855485\n",
       " -3.48898   -2.61088    -2.54628   …  -0.114264    1.67877    1.0606\n",
       " -2.11713   -3.73151    -2.36377       0.193305    2.10344   -0.487644\n",
       " -4.33978   -7.72135     1.19833       0.405462    0.987262  -3.32203\n",
       " -3.55214   -4.37545    -2.19178       1.12061     0.685728  -2.17152\n",
       " -3.32094   -3.80127    -0.629319      2.41431    -0.140225  -1.80684"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ztruth = compute_V(G, UR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU accelerated version\n",
    "the GPU compute_V uses `approxchol_lap_gpu()` (Actually directly using greedy version). The gpu version accelerates the computation inside a loop using gpu, except the preconditioning part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pcg_gpu (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some helper function\n",
    "cudot(cuva, cuvb) = reduce(+, cuva .* cuvb)\n",
    "cunorm(cuv) = sqrt(reduce(+, cuv .* cuv))\n",
    "\n",
    "\n",
    "# GPU accelerated PCG algorithm\n",
    "# mat is assumed to be a CuSparseMatrixCSC\n",
    "function pcg_gpu(mat::CuSparseMatrixCSC, b::Vector{Tval}, pre::Function;\n",
    "  tol::Real=1e-6, maxits=Inf, maxtime=Inf, verbose=false, pcgIts=Int[],\n",
    "  stag_test::Integer=0) where Tval\n",
    "\n",
    "local al::Tval\n",
    "\n",
    "n = size(mat,2)\n",
    "\n",
    "cub = CuVector(b)\n",
    "nb = cunorm(cub)\n",
    "\n",
    "# If input vector is zero, quit\n",
    "if nb == 0\n",
    "  return zeros(size(b))\n",
    "end\n",
    "\n",
    "x = CuVector(zeros(Tval,n)) # move these to GPU\n",
    "bestx = CuVector(zeros(Tval,n))\n",
    "bestnr = 1.0\n",
    "\n",
    "r = copy(cub) # the copy is still an Object on GPU\n",
    "z = CuVector(pre(Vector(r))) # first move r to CPU, apply precondition, then create an object on GPU\n",
    "p = copy(z) # p is an object on GPU\n",
    "\n",
    "rho = cudot(r, z) # make a dot project on GPU, rho is a scala\n",
    "best_rho = rho\n",
    "stag_count = 0\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "itcnt = 0\n",
    "while itcnt < maxits\n",
    "  itcnt = itcnt+1\n",
    "\n",
    "  q = mat*p # it is a CuSparse * CuVector, result is a CuVector\n",
    "\n",
    "  pq = cudot(p,q) # both p and q are CuVector, pq is a scala\n",
    "\n",
    "  if (pq < eps(Tval) || isinf(pq))\n",
    "    if verbose\n",
    "      println(\"PCG Stopped due to small or large pq\")\n",
    "    end\n",
    "    break\n",
    "  end\n",
    "\n",
    "  al = rho/pq # rho and pq are scalas, al is scala\n",
    "\n",
    "  # the following line could cause slowdown\n",
    "  if al*norm(p) < eps(Tval)*norm(x)\n",
    "    if verbose\n",
    "      println(\"PCG: Stopped due to stagnation.\")\n",
    "    end\n",
    "    break\n",
    "  end\n",
    "\n",
    "  x = al * p + x; # axpy(al, p, x)\n",
    "  r = -al * q + r; # axpy(-al, q, r)\n",
    "\n",
    "  nr = cunorm(r)/nb # nr is scala\n",
    "  if nr < bestnr\n",
    "    bestnr = nr\n",
    "    bestx = x\n",
    "  end\n",
    "  if nr < tol #Converged?\n",
    "      break\n",
    "  end\n",
    "\n",
    "  # here is the top of the code in numerical templates\n",
    "\n",
    "  z = CuVector(pre(Vector(r))) # first move r to CPU, apply precondition, then create an object on GPU\n",
    "\n",
    "  oldrho = rho\n",
    "  rho = cudot(z, r) # this is gamma in hypre.\n",
    "\n",
    "  if rho < best_rho*(1-1/stag_test)\n",
    "    best_rho = rho\n",
    "    stag_count = 0\n",
    "  else\n",
    "    if stag_test > 0\n",
    "      if best_rho > (1-1/stag_test)*rho\n",
    "        stag_count += 1\n",
    "        if stag_count > stag_test\n",
    "          println(\"PCG Stopped by stagnation test \", stag_test)\n",
    "          break\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "\n",
    "  if (rho < eps(Tval) || isinf(rho))\n",
    "    if verbose\n",
    "      println(\"PCG Stopped due to small or large rho\")\n",
    "    end\n",
    "    break\n",
    "  end\n",
    "\n",
    "  # the following would have higher accuracy\n",
    "  #       rho = sum(r.^2)\n",
    "\n",
    "  beta = rho/oldrho\n",
    "  if (beta < eps(Tval) || isinf(beta))\n",
    "    if verbose\n",
    "      println(\"PCG Stopped due to small or large beta\")\n",
    "    end\n",
    "    break\n",
    "  end\n",
    "\n",
    "  p = z + beta * p # p = z + beta*p\n",
    "\n",
    "  if (time() - t1) > maxtime\n",
    "      if verbose\n",
    "          println(\"PCG New stopped at maxtime.\")\n",
    "      end\n",
    "      break\n",
    "  end\n",
    "\n",
    "end\n",
    "\n",
    "if verbose\n",
    "  println(\"PCG stopped after: \", round((time() - t1),digits=3), \" seconds and \", itcnt, \" iterations with relative error \", (norm(r)/norm(b)), \".\")\n",
    "end\n",
    "\n",
    "if length(pcgIts) > 0\n",
    "  pcgIts[1] = itcnt\n",
    "end\n",
    "\n",
    "\n",
    "return Vector(bestx) # transfer back from GPU\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approxchol_lap_gpu (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this version using GPU pcg solver.\n",
    "function approxchol_lap_gpu(a::SparseMatrixCSC;\n",
    "  tol::Real=1e-6,\n",
    "  maxits=1000,\n",
    "  maxtime=Inf,\n",
    "  verbose=false,\n",
    "  pcgIts=Int[],\n",
    "  params=ApproxCholParams())\n",
    "\n",
    "  tol_ =tol\n",
    "  maxits_ =maxits\n",
    "  maxtime_ =maxtime\n",
    "  verbose_ =verbose\n",
    "  pcgIts_ =pcgIts\n",
    "\n",
    "  t1 = time()\n",
    "\n",
    "  la = lap(a) # a hit !?\n",
    "\n",
    "  llmat = Laplacians.LLmatp(a)\n",
    "  ldli = Laplacians.approxChol(llmat)\n",
    "  F(b) = Laplacians.LDLsolver(ldli, b)\n",
    "\n",
    "  if verbose\n",
    "    println(\"Using greedy degree ordering. Factorization time: \", time()-t1)\n",
    "    println(\"Ratio of operator edges to original edges: \", 2 * length(ldli.fval) / nnz(a))\n",
    "  end\n",
    "\n",
    "  if verbose\n",
    "      println(\"ratio of max to min diagonal of laplacian : \", maximum(diag(la))/minimum(diag(la)))\n",
    "  end\n",
    "\n",
    "  # Create Objects on GPU\n",
    "  cula = CuSparseMatrixCSC(la)\n",
    "\n",
    "  # can only pass la to GPU before computer happens\n",
    "  f(b;tol=tol_,maxits=maxits_, maxtime=maxtime_, verbose=verbose_, pcgIts=pcgIts_) = pcg_gpu(cula, b .- mean(b), F, tol=tol, maxits=maxits, maxtime=maxtime, pcgIts=pcgIts, verbose=verbose, stag_test = params.stag_test)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_V_gpu (generic function with 2 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_V_gpu(a, JLfac=4.0)\n",
    "  f = approxchol_lap_gpu(a,tol=1e-2); # a is the weight matrix loaded from file, nxn\n",
    "\n",
    "  V = zeros(n,k)\n",
    "  print(\"Time to solve Lap: \")\n",
    "  @time for i in 1:k\n",
    "    V[:,i] = f(UR[:,i]) # f is the linear solver, solve for x in Ax=b\n",
    "  end\n",
    "  \n",
    "  return V # V here is the Z in paper\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to solve Lap:   0.589542 seconds (37.73 k allocations: 1.358 GiB, 4.23% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000×52 Matrix{Float64}:\n",
       " -0.136154   0.221333   -0.101415  …  -0.864206   -0.543875  -0.637303\n",
       " -1.33927    0.101885    0.94094       0.274264   -0.600522  -2.22005\n",
       " -0.496564   0.31435    -0.738116      0.151975   -0.148009  -1.35155\n",
       " -2.01569    0.574576    1.47215       0.420305    0.121864  -0.233282\n",
       " -1.09486   -0.782095   -0.288486      1.64332    -0.30036   -2.40688\n",
       " -0.653569  -0.0810101  -1.21161   …   0.017349    0.272805  -0.0757558\n",
       "  1.74127   -0.510598   -0.591395      0.0861215   0.381633   0.709085\n",
       " -2.00904    0.142638    2.17329      -0.726002    0.188597  -1.00654\n",
       " -1.25829   -0.407155    3.32424       1.46801    -0.522331   0.350373\n",
       " -0.395821   0.852829    0.687504     -1.16199     0.182291  -1.70919\n",
       " -3.02147    1.00814     0.209637  …   0.454204    0.171743  -3.37195\n",
       " -0.501783  -1.26335    -2.27705       1.20961     0.949149   0.77482\n",
       "  0.302677  -0.933872   -2.35225      -1.79625    -0.591203  -0.496129\n",
       "  ⋮                                ⋱               ⋮         \n",
       " -6.79343   -5.61047     1.4999       -1.96425     3.51561    1.9123\n",
       " -6.16174   -5.93651     2.5438       -0.69752    -0.217299   3.26072\n",
       " -6.71098   -6.66004     0.128651  …  -1.74221    -2.52456    2.03762\n",
       " -2.13122   -6.09355    -2.79915      -3.49407     3.3962     2.94343\n",
       " -3.96234   -5.07368    -0.997027     -2.07447     2.27635   -0.267876\n",
       " -5.40193   -3.49376    -1.46473      -0.859093    0.471503   0.938455\n",
       " -1.79623   -5.27965    -0.54147      -0.776543    0.800157  -0.855485\n",
       " -3.48898   -2.61088    -2.54628   …  -0.114264    1.67877    1.0606\n",
       " -2.11713   -3.73151    -2.36377       0.193305    2.10344   -0.487644\n",
       " -4.33978   -7.72135     1.19833       0.405462    0.987262  -3.32203\n",
       " -3.55214   -4.37545    -2.19178       1.12061     0.685728  -2.17152\n",
       " -3.32094   -3.80127    -0.629319      2.41431    -0.140225  -1.80684"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zgpu = compute_V_gpu(G, UR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.211340116499415e-16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as the pcg will exit based on convergence condition, consider the result is correct when result is close\n",
    "diff = Zgpu - Ztruth\n",
    "mean(abs.(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.717221104926338e-6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abs(minimum(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×100 CuSparseMatrixCSC{Float64, Int32} with 1982 stored entries:\n",
       "⠆⠷⠀⣄⠂⡢⠦⠔⡤⡢⠢⢥⠀⠇⡠⠁⢁⠃⣠⡏⠟⠂⢴⠠⢘⡠⢞⠂⢻⠌⠚⡌⠐⠈⢸⢄⢄⡌⠼⠬\n",
       "⢒⠀⠐⣆⡔⢂⠔⡒⢤⠎⠠⠄⠨⠧⠠⠆⡄⠜⡎⠦⠠⠫⠄⠠⠄⢰⠔⡁⠰⠜⠦⠠⠄⠨⡨⠈⢘⠤⢸⠄\n",
       "⠢⠣⠀⡐⠴⠇⡡⡠⡤⠦⠠⡈⠮⢆⢐⡋⠄⠥⠄⠇⠠⢒⢢⢤⠠⢀⠴⢀⠤⢀⠐⠂⡬⠊⠉⠄⠨⠤⠁⠘\n",
       "⠂⠓⠡⡀⢔⠦⠀⠅⠄⡜⢈⡀⠀⠀⠉⡄⠅⡄⢨⠄⠐⢄⡀⢲⠔⢰⠀⢀⠠⢀⢠⠂⠭⠂⢭⢀⡃⡍⠲⠅\n",
       "⠜⠀⢄⠄⠂⠴⠔⠥⢔⢤⠄⠅⡌⠉⠀⢭⠁⠡⢀⢔⠈⠰⢌⠐⣐⠁⠠⡀⠠⠂⠨⠭⡬⠤⠒⠌⠐⠅⡢⠁\n",
       "⠬⠂⠰⡅⡁⠙⠤⡀⠀⠮⢼⠤⡢⢑⢲⢄⣀⡷⡙⠈⢔⠪⠤⠁⡝⠀⢦⠀⡶⡀⠐⠄⡤⠇⢨⡗⠂⠋⢈⡂\n",
       "⠀⠎⠘⠤⠀⡦⠾⡁⠀⠎⡈⡀⡐⠌⠁⡀⠐⢆⢘⡐⢅⠀⠜⢴⢂⢑⢅⡸⢡⣊⢻⠆⠠⠤⣡⢸⢨⡈⠲⠬\n",
       "⠦⠠⢄⠀⢘⠗⠀⠠⠆⣆⠁⠤⠤⠄⠔⣚⡁⡢⡀⠗⡦⠡⠡⠤⡉⠅⢨⠢⢄⠀⡠⡌⣔⠂⣠⣃⣗⠐⢤⠃\n",
       "⠁⠀⢡⡇⠀⠀⠐⠳⠣⡦⠄⢍⢓⠦⠲⠲⠤⠣⠀⡍⡨⡠⠠⠤⣥⠀⢠⠈⠼⠅⣠⠪⢄⠠⠸⠄⠋⠡⠀⠆\n",
       "⠀⠑⣔⠅⠢⠢⢀⠐⠡⢀⠆⠄⠠⡲⠄⡃⢨⡼⠁⠅⣸⠠⠏⠤⢡⠐⠥⠄⢀⠀⢪⠅⡼⠤⢸⠵⢮⠨⢬⠰\n",
       "⡖⡧⢀⢎⢠⣃⢂⠗⠑⠋⢢⠷⠀⠡⡂⠷⡀⠂⠤⢕⠋⡃⠈⠀⠴⠋⠣⡰⢚⠀⠎⢦⠒⡚⠐⠧⠔⠐⠊⢐\n",
       "⠠⠁⢀⢖⠘⠂⠢⠒⠂⢶⢆⡅⠀⠠⣔⠅⠂⡅⢈⢄⡐⠒⢤⠒⠊⠘⡑⡐⢐⢐⠁⠳⣘⣐⢰⠔⡰⢒⠚⠊\n",
       "⢀⠒⠀⡎⢀⠢⠠⡀⠂⢒⡔⠅⠄⣲⠁⡄⠀⢪⠈⠜⡒⠀⢈⠐⣔⠆⠢⠵⢸⠪⢰⠀⠫⢑⣈⠀⠚⢺⢖⢀\n",
       "⠘⠎⠀⡺⠪⠑⠐⠂⠄⠓⠂⠒⠊⣦⠐⠆⠐⠊⡀⡃⠰⠀⡨⠃⢘⡤⢚⡄⣣⡐⠞⢁⠒⠕⠘⠂⢌⢨⢐⠆\n",
       "⠐⡲⠔⡊⠖⠋⢊⠆⠑⠐⡀⠡⠆⠁⡀⠀⠐⠄⠂⠃⠔⠀⠌⡁⠀⠪⠐⠐⠒⠃⠊⠲⡷⢐⠐⣂⠲⡣⠲⠰\n",
       "⡄⣐⢰⠄⠀⡈⢘⠔⢁⡔⡚⡤⠒⠒⢂⢃⠁⠂⠘⣖⣲⠊⢙⠀⡊⠁⢢⠩⠈⠂⢠⠀⠲⠀⠁⡦⠒⠂⠊⠒\n",
       "⠀⡇⠂⠒⠀⠠⡂⡂⠜⡃⡀⠂⡠⠁⠀⢠⡛⠠⠂⢓⢢⠠⠪⢑⠰⡆⠠⠂⠨⠩⠒⠀⠰⠂⠲⢂⠜⠀⠺⣦\n",
       "⡒⡃⠓⠆⢊⠛⠀⠐⢀⠅⠁⠀⠃⠂⠀⣂⠅⢂⡓⣊⢜⠒⠰⠂⢇⡈⠐⢂⠫⠐⠐⠒⠊⢂⣸⡀⡛⠊⢠⠠\n",
       "⡂⠲⠨⡂⡀⠡⠐⠒⡓⡼⠠⠂⠍⢂⠐⠂⠲⡄⢄⢀⢀⠁⡐⠰⠲⡹⠘⠀⠸⠙⢆⡺⢰⠄⠚⡠⡈⠠⢈⠒\n",
       "⠁⡀⡆⡆⣷⢧⢚⡔⡤⠵⠄⡅⠘⡠⢀⠊⠤⡶⢔⠃⢈⠂⢀⠀⠃⠤⢻⠌⢂⠋⢲⠴⠞⠁⠀⡊⡚⠀⢈⠀"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = CuSparseMatrixCSC(sprandn(100, 100, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:10000; cm * cv; end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.215722326703602"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduce(+, cv .* cv) # dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Float64}:\n",
       " 0.7124631363372693\n",
       " 0.265700079127287\n",
       " 0.26485347658042224\n",
       " 0.6678531149154389\n",
       " 0.9922126352602408\n",
       " 0.3667024377203091\n",
       " 0.4693941714765961\n",
       " 0.2703520496144789\n",
       " 0.2260796532265591\n",
       " 0.04660779725173281\n",
       " ⋮\n",
       " 0.6692765766444105\n",
       " 0.09336537126440936\n",
       " 0.5908781827065405\n",
       " 0.9657135359954367\n",
       " 0.5803623647514778\n",
       " 0.8744399568648321\n",
       " 0.1712150273251376\n",
       " 0.50326781043447\n",
       " 0.10453535698078131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tt = Vector(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cudot (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cudot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element CuArray{Float64, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 0.7124631363372693\n",
       " 0.265700079127287\n",
       " 0.26485347658042224\n",
       " 0.6678531149154389\n",
       " 0.9922126352602408\n",
       " 0.3667024377203091\n",
       " 0.4693941714765961\n",
       " 0.2703520496144789\n",
       " 0.2260796532265591\n",
       " 0.04660779725173281\n",
       " ⋮\n",
       " 0.6692765766444105\n",
       " 0.09336537126440936\n",
       " 0.5908781827065405\n",
       " 0.9657135359954367\n",
       " 0.5803623647514778\n",
       " 0.8744399568648321\n",
       " 0.1712150273251376\n",
       " 0.50326781043447\n",
       " 0.10453535698078131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "copy(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.120129131838728"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sqrt(dot(tt, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix{Float64}\u001b[90m (alias for \u001b[39m\u001b[90mArray{Float64, 2}\u001b[39m\u001b[90m)\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "typeof(UR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseMatrixCSC{Float64, Int64}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "typeof(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cudot (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cudot(cuv) = reduce(+, cuv .* cuv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element CuArray{Float64, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 3.5623156816863464\n",
       " 1.328500395636435\n",
       " 1.3242673829021112\n",
       " 3.3392655745771944\n",
       " 4.961063176301204\n",
       " 1.8335121886015453\n",
       " 2.3469708573829804\n",
       " 1.3517602480723945\n",
       " 1.1303982661327954\n",
       " 0.23303898625866404\n",
       " ⋮\n",
       " 3.3463828832220526\n",
       " 0.4668268563220468\n",
       " 2.9543909135327024\n",
       " 4.8285676799771835\n",
       " 2.9018118237573893\n",
       " 4.3721997843241605\n",
       " 0.856075136625688\n",
       " 2.51633905217235\n",
       " 0.5226767849039066"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv * 2*2 + cv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
