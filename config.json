{
    "Reddit": {
        "num_nodes": 232965,
        "num_layers": 2,
        "epochs": 50,
        "drop_rate" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995, 0.998, 0.999],
        "degree_thres" : [2180, 1290, 878, 627, 449, 315, 209, 125, 56, 27, 5, 4, 3, 2, 1],
        "er_epsilon" : [0.035, 0.0459, 0.0566, 0.0683, 0.0823, 0.1, 0.125, 0.166, 0.254, 0.376, 0.424, 0.495, 0.61, 0.88, 1.26, 2, 2.8],
        "degree_thres_to_drop_rate_map": {
            "2180": 0.1 ,
            "1290": 0.2,
            "878": 0.3,
            "627": 0.4,
            "449": 0.5,
            "315": 0.6,
            "209": 0.7,
            "125": 0.8,
            "56": 0.9,
            "27": 0.949,
            "5": 0.99,
            "4": 0.992,
            "3": 0.994,
            "2": 0.996,
            "1": 0.998
        }, 
        "er_epsilon_to_drop_rate_map": {
            "0.035": 0.1,
            "0.0459": 0.2,
            "0.0566": 0.3,
            "0.0683": 0.4,
            "0.0823": 0.5,
            "0.1": 0.6,
            "0.125": 0.7,
            "0.166": 0.8,
            "0.254": 0.9,
            "0.376": 0.95,
            "0.424": 0.96,
            "0.495": 0.97,
            "0.61": 0.98,
            "0.88": 0.99,
            "1.26": 0.995,
            "2": 0.998,
            "2.8": 0.999
        },
        "random_prune_inference_batch_size_dict1": {
            "0.0": 20000, 
            "0.1": 23000, 
            "0.2": 25000, 
            "0.3": 31000, 
            "0.4": 38000, 
            "0.5": 41000, 
            "0.6": 51000, 
            "0.7": 68000, 
            "0.75": 88000, 
            "0.8": 110000, 
            "0.85": 230000, 
            "0.9": 230000, 
            "0.95": 232965, 
            "0.96": 232965, 
            "0.97": 232965, 
            "0.98": 232965, 
            "0.99": 232965, 
            "0.995": 232965, 
            "0.998": 232965, 
            "0.999": 232965
        },
        "degree_prune_inference_batch_size_dict1": {
            "2180": 24000,
            "1290": 27000,
            "878": 29000,
            "627": 37000, 
            "449": 45000, 
            "315": 55000, 
            "209": 70000, 
            "125": 110000,
            "56": 230000, 
            "27": 232965, 
            "5": 232965, 
            "4": 232965, 
            "3": 232965, 
            "2": 232965, 
            "1": 232965 
        }
    },

    "Reddit2": {
        "num_nodes": 232965,
        "num_layers": 2,
        "epochs": 150,
        "drop_rate" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995],
        "degree_thres" : [302, 177, 121, 87, 64, 48, 34, 22, 10, 5, 1],
        "er_epsilon": [0.094, 0.122, 0.148, 0.176, 0.209, 0.25, 0.306, 0.395, 0.594, 0.87, 2],
        "degree_thres_to_drop_rate_map": {
            "302": 0.1 ,
            "177": 0.2,
            "121": 0.3,
            "87": 0.4,
            "64": 0.5,
            "48": 0.6,
            "34": 0.7,
            "22": 0.8,
            "10": 0.905,
            "5": 0.951,
            "1": 0.99
        },
        "er_epsilon_to_drop_rate_map": {
            "0.094": 0.1,
            "0.122": 0.2,
            "0.148": 0.3,
            "0.176": 0.4,
            "0.209": 0.5,
            "0.25": 0.6,
            "0.306": 0.7,
            "0.395": 0.8,
            "0.594": 0.9,
            "0.87": 0.95,
            "2": 0.99
        },
        "random_prune_inference_batch_size_dict1": {
            "0.0": 115000, 
            "0.1": 120000, 
            "0.2": 230000, 
            "0.3": 230000, 
            "0.4": 230000, 
            "0.5": 230000, 
            "0.6": 232965, 
            "0.7": 232965, 
            "0.75": 232965, 
            "0.8": 232965, 
            "0.85": 232965, 
            "0.9": 232965, 
            "0.95": 232965, 
            "0.96": 232965, 
            "0.97": 232965, 
            "0.98": 232965, 
            "0.99": 232965, 
            "0.995": 232965
        },
        "degree_prune_inference_batch_size_dict1": {
            "302": 120000,
            "177": 140000, 
            "121": 190000, 
            "87": 220000, 
            "64": 230000, 
            "48": 232965, 
            "34": 232965, 
            "22": 232965, 
            "10": 232965, 
            "5": 232965, 
            "1": 232965 
        }
    },

    "ogbn_products": {
        "num_nodes": 2449029,
        "num_layers": 3,
        "epochs": 50,
        "drop_rate" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98],
        "degree_thres" : [244, 127, 84, 60, 44, 31, 21, 13, 9, 6, 3, 2, 1],
        "er_epsilon": [0.132, 0.17, 0.206, 0.246, 0.294, 0.356, 0.442, 0.581, 0.885, 1.3, 1.47, 1.71, 2.1],
        "degree_thres_to_drop_rate_map": {
            "244": 0.1 ,
            "127": 0.2,
            "84": 0.3,
            "60": 0.4,
            "44": 0.5,
            "31": 0.6,
            "21": 0.7,
            "13": 0.8,
            "9": 0.85,
            "6": 0.894,
            "3": 0.944,
            "2": 0.962,
            "1": 0.981
        },
        "er_epsilon_to_drop_rate_map": {
            "0.132": 0.1,
            "0.17": 0.2,
            "0.206": 0.3,
            "0.246": 0.4,
            "0.294": 0.5,
            "0.356": 0.6,
            "0.442": 0.7,
            "0.581": 0.8,
            "0.885": 0.9,
            "1.3": 0.95,
            "1.47": 0.96,
            "1.71": 0.97,
            "2.1": 0.98
        },
        "random_prune_inference_batch_size_dict1": {
            "0.0": 64000, 
            "0.1": 71000, 
            "0.2": 80000, 
            "0.3": 92000, 
            "0.4": 188000, 
            "0.5": 272000, 
            "0.6": 330000, 
            "0.7": 610000, 
            "0.75": 780000, 
            "0.8": 750000, 
            "0.85": 2000000, 
            "0.9": 2400000, 
            "0.95": 2449029, 
            "0.96": 2449029, 
            "0.97": 2449029, 
            "0.98": 2449029
        },
        "degree_prune_inference_batch_size_dict1": {
            "244": 60000,
            "127": 75000,
            "84": 80000, 
            "60": 100000, 
            "44": 200000, 
            "31": 250000, 
            "21": 600000, 
            "13": 900000, 
            "9": 2200000, 
            "6": 2300000, 
            "3": 2449029, 
            "2": 2449029, 
            "1": 2449029 
        }
    },

    "sk_2005": {
        "num_nodes": 50636152,
        "num_layers": 3,
        "epochs": 50,
        "drop_rate" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995, 0.999],
        "degree_thres" : [],
        "er_epsilon": [],
        "degree_thres_to_drop_rate_map": {
        },
        "er_epsilon_to_drop_rate_map": {
        },
        "random_prune_inference_batch_size_dict1": {
        },
        "degree_prune_inference_batch_size_dict1": {
        }
    },

    "AGATHA_2015": {
        "num_nodes": 183964078,
        "num_layers": 3,
        "epochs": 50,
        "drop_rate" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995, 0.999],
        "degree_thres" : [],
        "er_epsilon": [],
        "degree_thres_to_drop_rate_map": {
        },
        "er_epsilon_to_drop_rate_map": {
        },
        "random_prune_inference_batch_size_dict1": {
        },
        "degree_prune_inference_batch_size_dict1": {
        }
    }
}
